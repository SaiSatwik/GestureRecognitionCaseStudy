{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VjGQ04S6olm",
        "outputId": "3d58c882-b19b-4ed6-e0b1-fe9a5768e6b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install pillow\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fy6cQbuYnjm4"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.misc import imread, imresize\n",
        "import datetime\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import abc\n",
        "from sys import getsizeof"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIyMGwpOnjm5"
      },
      "source": [
        "We set the random seed so that the results don't vary drastically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lbxACBcznjm5"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)\n",
        "#tf.random.set_seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JCtEdwV3njm6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X0OCffMnjm6"
      },
      "source": [
        "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s7BXbGkdnjm6"
      },
      "outputs": [],
      "source": [
        "# importing some other libraries which will be needed for model building.\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT8mpZqm8l7O",
        "outputId": "fb50749c-cbae-4cb6-82de-2db15b733ea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abzbqDoi8mCB",
        "outputId": "efda308d-4125-4ecc-c109-dda0a216ea8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive\n"
          ]
        }
      ],
      "source": [
        "cd '/content/gdrive/My Drive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDK2zb2-81Aa",
        "outputId": "f8644dbc-ea59-4fc5-bc67-6342d5cc7047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Project_data.zip\n",
            "replace Project_data/train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip Project_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l3OkNwinjm7"
      },
      "outputs": [],
      "source": [
        "\n",
        "project_folder='Project_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQLRAju7njm7"
      },
      "outputs": [],
      "source": [
        "# function to plot the training/validation accuracies and losses\n",
        "\n",
        "def plot(data):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
        "    axes[0].plot(data.history['loss'])   \n",
        "    axes[0].plot(data.history['val_loss'])\n",
        "    axes[0].legend(['loss','val_loss'])\n",
        "\n",
        "    axes[1].plot(data.history['categorical_accuracy'])   \n",
        "    axes[1].plot(data.history['val_categorical_accuracy'])\n",
        "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "infjahFDnjm8"
      },
      "source": [
        "## Generator\n",
        "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd4SNs_Rnjm8"
      },
      "outputs": [],
      "source": [
        "class ModelBuilder():\n",
        "    # initialisng the path where project data resides\n",
        "    def initialize_path(self, project_folder):\n",
        "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())\n",
        "        self.val_doc = np.random.permutation(open(project_folder + '/' + 'val.csv').readlines())\n",
        "        self.train_path = project_folder + '/' + 'train'\n",
        "        self.val_path = project_folder + '/' + 'val'\n",
        "        self.num_train_sequences = len(self.train_doc)\n",
        "        self.num_val_sequences = len(self.val_doc)\n",
        "\n",
        "    # initialising the batch size, frames to sample and the no. of epochs\n",
        "    def initialize_hyperparams(self, frames_to_sample = 30, batch_size = 20, num_epochs = 20):\n",
        "        self.frames_to_sample = frames_to_sample\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "\n",
        "    # initialising the image properties    \n",
        "    def initialize_image_properties(self, image_height = 100, image_width = 100):\n",
        "        self.image_height = image_height\n",
        "        self.image_width = image_width\n",
        "        self.channels = 3\n",
        "        self.num_classes = 5\n",
        "        self.total_frames = 30\n",
        "        \n",
        "    # The generator function        \n",
        "    def generator(self,source_path, folder_list, augment=False):\n",
        "        img_idx = np.round(np.linspace(0, self.total_frames-1, self.frames_to_sample)).astype(int)\n",
        "        batch_size=self.batch_size\n",
        "        while True:\n",
        "            t = np.random.permutation(folder_list)\n",
        "            num_batches = len(t)//batch_size\n",
        "        \n",
        "            for batch in range(num_batches): \n",
        "                batch_data, batch_labels = self.one_batch_data(source_path, t, batch,batch_size, img_idx,augment)\n",
        "                yield batch_data, batch_labels \n",
        "\n",
        "            remaining_seq = len(t)%batch_size\n",
        "        \n",
        "            if (remaining_seq != 0):\n",
        "                batch_data, batch_labels = self.one_batch_data(source_path, t, num_batches,batch_size, img_idx,augment, remaining_seq)\n",
        "                yield batch_data, batch_labels \n",
        "    \n",
        "    \n",
        "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
        "    \n",
        "        seq_len = remaining_seq if remaining_seq else batch_size\n",
        "    \n",
        "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
        "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
        "    \n",
        "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
        "\n",
        "        \n",
        "        for folder in range(seq_len): \n",
        "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
        "            for idx,item in enumerate(img_idx):\n",
        "                #performing image reading and resizing\n",
        "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                image_resized=imresize(image,(self.image_height,self.image_width,3))\n",
        "            \n",
        "                #normalizing the images\n",
        "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
        "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
        "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
        "            \n",
        "                if (augment):\n",
        "                    shifted = cv2.warpAffine(image, \n",
        "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
        "                                            (image.shape[1], image.shape[0]))\n",
        "                    \n",
        "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
        "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
        "                    # cropping the images to have the targeted gestures and remove the noise from the images.\n",
        "                    cropped=shifted[x0:x1,y0:y1,:]\n",
        "                    \n",
        "                    image_resized=imresize(cropped,(self.image_height,self.image_width,3))\n",
        "                    \n",
        "                    #shifted = cv2.warpAffine(image_resized, \n",
        "                    #                        np.float32([[1, 0, np.random.randint(-3,3)],[0, 1, np.random.randint(-3,3)]]), \n",
        "                    #                        (image_resized.shape[1], image_resized.shape[0]))\n",
        "            \n",
        "                    batch_data_aug[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
        "                    batch_data_aug[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
        "                    batch_data_aug[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
        "                \n",
        "            \n",
        "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            \n",
        "    \n",
        "        if (augment):\n",
        "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
        "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
        "\n",
        "        \n",
        "        return(batch_data,batch_labels)\n",
        "    \n",
        "    \n",
        "    def train_model(self, model, augment_data=False):\n",
        "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
        "        val_generator = self.generator(self.val_path, self.val_doc)\n",
        "\n",
        "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "        if not os.path.exists(model_name):\n",
        "            os.mkdir(model_name)\n",
        "        \n",
        "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
        "        \n",
        "        earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
        "        callbacks_list = [checkpoint, LR, earlystop]\n",
        "\n",
        "        if (self.num_train_sequences%self.batch_size) == 0:\n",
        "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
        "        else:\n",
        "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
        "\n",
        "        if (self.num_val_sequences%self.batch_size) == 0:\n",
        "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
        "        else:\n",
        "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
        "    \n",
        "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
        "                            callbacks=callbacks_list, validation_data=val_generator, \n",
        "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
        "        return history\n",
        "\n",
        "        \n",
        "    @abc.abstractmethod\n",
        "    def define_model(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9GaCxpknjm9"
      },
      "source": [
        "## Model\n",
        "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Um9IQULnjm-"
      },
      "source": [
        "## Sample Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrHxN9Zonjm-"
      },
      "outputs": [],
      "source": [
        "class ModelConv3D1(ModelBuilder):\n",
        "    \n",
        "    def define_model(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same'))\n",
        "\n",
        "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same'))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same'))\n",
        "\n",
        "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same'))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = tf.keras.optimizers.Adam()\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEd90bIxnjm-",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "conv_3d1 = ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=10,num_epochs=1)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "conv_3d1_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQcQ8I0Tnjm_"
      },
      "source": [
        "##### Sample Cropping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHaxCYLMnjm_"
      },
      "outputs": [],
      "source": [
        "test_generator=ModelConv3D1()\n",
        "test_generator.initialize_path(project_folder)\n",
        "test_generator.initialize_image_properties(image_height=160,image_width=160)\n",
        "test_generator.initialize_hyperparams(frames_to_sample=30,batch_size=3,num_epochs=1)\n",
        "\n",
        "g=test_generator.generator(test_generator.val_path,test_generator.val_doc,augment=True)\n",
        "batch_data, batch_labels=next(g)\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "axes[0].imshow(batch_data[0,15,:,:,:])   \n",
        "axes[1].imshow(batch_data[3,15,:,:,:])   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yli-eh5bnjm_"
      },
      "source": [
        "## Experimenting with Image resolution, number of frames to use and batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY-pLFyPnjm_"
      },
      "source": [
        "### We had hit the limit on memory resources with image resolution of 160x160 with 30 frames and batch_size of 40...we get the below error\n",
        "\n",
        "ResourceExhaustedError: OOM when allocating tensor with shape[40,16,30,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbLWDKLfnjm_"
      },
      "outputs": [],
      "source": [
        "print(\"Memory util is {} Gigs\". format(getsizeof(np.zeros((40,16,30,160,160)))/(1024*1024*1024)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPxYEd7LnjnA"
      },
      "source": [
        "##### So lets trade-off between these parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "j_-ZnZjNnjnA"
      },
      "source": [
        "##### Below are the experiments to see how training time is affected by image resolution, number of images in sequence and batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29NnAnYZnjnA"
      },
      "outputs": [],
      "source": [
        "conv_3d1 = ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height = 100, image_width = 100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample = 15, batch_size = 30, num_epochs = 2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16mEaVkJnjnA"
      },
      "outputs": [],
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=20,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeI7dIF9njnA"
      },
      "outputs": [],
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=15,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig9tudMJnjnA"
      },
      "source": [
        "- We can observe from above experiments that \"image resolution\" and \"number of frames\" in sequence have more impact on training time than \"batch_size\"\n",
        "- We can consider the Batch Size around 15-40\n",
        "- Change the resolution 160\\*160, 120\\*120 according the model performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLM5nLk7njnB"
      },
      "source": [
        "## Model 1\n",
        "### Base Model - Batch Size = 40 and No. of Epochs = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72IrFuF_njnB"
      },
      "outputs": [],
      "source": [
        "class ModelConv3D1(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = tf.keras.optimizers.Adam()\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5JI84qUnjnB"
      },
      "outputs": [],
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=20,batch_size=40,num_epochs=15)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "conv_3d1_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMm1CBqqnjnB"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "history_model1 = conv_3d1.train_model(conv_3d1_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIGejajpnjnB"
      },
      "outputs": [],
      "source": [
        "plot(history_model1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63ujv-2BnjnB"
      },
      "source": [
        "##### Model is clearly overfitting. :("
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVHZK11LnjnC"
      },
      "source": [
        "## Model 2  \n",
        "### Adding dropout layers - Batch Size = 20 and No. of Epochs = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3FWZnkbnjnC"
      },
      "outputs": [],
      "source": [
        "conv_3d2=ModelConv3D1()\n",
        "conv_3d2.initialize_path(project_folder)\n",
        "conv_3d2.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d2.initialize_hyperparams(frames_to_sample=20,batch_size=20,num_epochs=25)\n",
        "conv_3d2_model=conv_3d2.define_model(dense_neurons=256,dropout=0.5)\n",
        "conv_3d2_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNDPMjGgnjnC"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", conv_3d2_model.count_params())\n",
        "history_model2=conv_3d2.train_model(conv_3d2_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Akz4HqVZnjnC"
      },
      "outputs": [],
      "source": [
        "plot(history_model2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A48O6nM0njnC"
      },
      "source": [
        "##### We can see  val_loss did not improve from 1.24219 so earlystopping stops the epoch automatically!! \n",
        "- Last Epoch stop on 15/25!! good job earlystopping ;)\n",
        "- Best weights save automatically. The validation accuracy of 52% and training accuracy of 65%. Next we will try to reduce the filter size and image resolution and see if get better results. Moreover since we see minor oscillations  in loss, let's try lowering the learning rate to 0.0002"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ckwq3LAnjnC"
      },
      "source": [
        "## Model 3 \n",
        "### Reduce filter size to (2,2,2) and image res to 120 x  120, - Batch Size = 30 and No. of Epochs = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ks9wUfP3njnC"
      },
      "outputs": [],
      "source": [
        "class ModelConv3D3(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "        \n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJGBdYDcnjnD"
      },
      "outputs": [],
      "source": [
        "conv_3d3=ModelConv3D3()\n",
        "conv_3d3.initialize_path(project_folder)\n",
        "conv_3d3.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d3.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=25)\n",
        "conv_3d3_model=conv_3d3.define_model(filtersize=(2,2,2),dense_neurons=256,dropout=0.5)\n",
        "conv_3d3_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9oPcMnInjnD"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", conv_3d3_model.count_params())\n",
        "history_model3=conv_3d3.train_model(conv_3d3_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej1kWF-FnjnD"
      },
      "outputs": [],
      "source": [
        "plot(history_model3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgxeJI5cnjnD"
      },
      "source": [
        "##### Model has a  best validation accuracy of 72% and training accuracy of 76% . Also we were able to reduce the parameter size by half the earlier model. Let's trying adding more layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvD1n0VrnjnD"
      },
      "source": [
        "## Model 4 - \n",
        "### Adding more layers - Batch Size = 20 and No. of Epochs = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMzg4lKgnjnD"
      },
      "outputs": [],
      "source": [
        "class ModelConv3D4(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam()\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF4ZelhnnjnD"
      },
      "outputs": [],
      "source": [
        "conv_3d4=ModelConv3D4()\n",
        "conv_3d4.initialize_path(project_folder)\n",
        "conv_3d4.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d4.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
        "conv_3d4_model=conv_3d4.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.5)\n",
        "conv_3d4_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQc7JJX8njnE"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", conv_3d4_model.count_params())\n",
        "history_model4=conv_3d4.train_model(conv_3d4_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jivNbrmTnjnE"
      },
      "outputs": [],
      "source": [
        "plot(history_model4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-85eRQ9njnE"
      },
      "source": [
        "##### With more layers we dont see much performance improvement. We get a best validation accuracy of 76% . Let's try adding dropouts at the convolution layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygcFPbOZnjnE"
      },
      "source": [
        "## Model 5 \n",
        "### Adding dropout at convolution layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RwPQv_xnjnE"
      },
      "outputs": [],
      "source": [
        "class ModelConv3D5(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam()\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKnmPmnAnjnE"
      },
      "outputs": [],
      "source": [
        "conv_3d5=ModelConv3D5()\n",
        "conv_3d5.initialize_path(project_folder)\n",
        "conv_3d5.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d5.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=15)\n",
        "conv_3d5_model=conv_3d5.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.25)\n",
        "conv_3d5_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QDIsslLnjnE"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", conv_3d5_model.count_params())\n",
        "history_model5=conv_3d5.train_model(conv_3d5_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c36GsiosnjnF"
      },
      "outputs": [],
      "source": [
        "plot(history_model5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "vXX9hiXHnjnF"
      },
      "source": [
        " __Ohh! Overfitting again!! Adding dropouts has further reduced validation accuracy as the model doesn't seem to generalise well.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obqq42y-njnF"
      },
      "source": [
        "##### All the experimental models above have more than 1 million parameters. Let's try to reduce the model size and see the performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgDyPcp9njnF"
      },
      "source": [
        "## Model 6 \n",
        "### Reducing the number of parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyradtXjnjnF"
      },
      "outputs": [],
      "source": [
        "class ModelConv3D6(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jaKYBh1njnF"
      },
      "outputs": [],
      "source": [
        "conv_3d6=ModelConv3D6()\n",
        "conv_3d6.initialize_path(project_folder)\n",
        "conv_3d6.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d6.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=20)\n",
        "conv_3d6_model=conv_3d6.define_model(dense_neurons=128,dropout=0.25)\n",
        "conv_3d6_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSmmb051njnF"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", conv_3d6_model.count_params())\n",
        "history_model6=conv_3d6.train_model(conv_3d6_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkJXhAcbnjnF"
      },
      "outputs": [],
      "source": [
        "plot(history_model6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "pSJR3wLynjnG"
      },
      "source": [
        "###### For the above low memory foot print model, we get the best validation accuracy of 74%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tMxr4nNnjnG"
      },
      "source": [
        "## Model 7 - Reducing the number of parameters again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUrSZIwNnjnG"
      },
      "outputs": [],
      "source": [
        "class ModelConv3D7(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (3, 3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2wnjXvEnjnG"
      },
      "outputs": [],
      "source": [
        "conv_3d7=ModelConv3D7()\n",
        "conv_3d7.initialize_path(project_folder)\n",
        "conv_3d7.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d7.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
        "conv_3d7_model=conv_3d7.define_model(dense_neurons=64,dropout=0.25)\n",
        "conv_3d7_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec2G2xP7njnG"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", conv_3d7_model.count_params())\n",
        "history_model7=conv_3d7.train_model(conv_3d7_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR8ALVXAnjnG"
      },
      "outputs": [],
      "source": [
        "plot(history_model7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcgHiH0EnjnG"
      },
      "source": [
        "###### For the above low memory foot print model the best validation accuracy of 73%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyWDLiI_njnG"
      },
      "source": [
        "## Model 8 - CNN- LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoUjb6T7njnH"
      },
      "outputs": [],
      "source": [
        "class RNNCNN1(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
        "                                  input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        #model.add(TimeDistributed(Conv2D(512, (2, 2) , padding='valid', activation='relu')))\n",
        "       # model.add(TimeDistributed(BatchNormalization()))\n",
        "       # model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "\n",
        "        model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "\n",
        "        model.add(LSTM(lstm_cells))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(self.num_classes, activation='softmax'))\n",
        "        optimiser = optimizers.Adam()\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sXcBo6enjnH"
      },
      "outputs": [],
      "source": [
        "rnn_cnn1=RNNCNN1()\n",
        "rnn_cnn1.initialize_path(project_folder)\n",
        "rnn_cnn1.initialize_image_properties(image_height=120,image_width=120)\n",
        "rnn_cnn1.initialize_hyperparams(frames_to_sample=18,batch_size=20,num_epochs=20)\n",
        "rnn_cnn1_model=rnn_cnn1.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
        "rnn_cnn1_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFTCYWPWnjnH"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", rnn_cnn1_model.count_params())\n",
        "history_model8=rnn_cnn1.train_model(rnn_cnn1_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDeM4hbbnjnH"
      },
      "outputs": [],
      "source": [
        "plot(history_model8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "nONq_3oXnjnH"
      },
      "source": [
        "##### For CNN - LSTM model we get a best validation accuracy of 85%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jYrHGAvnjnH"
      },
      "source": [
        "As we see more cases of overfitting, lets augment the data with ***slight rotation*** as well and run the same set of models again"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYczHH8RnjnH"
      },
      "source": [
        "## Let's apply some data augmentation & check the model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN1N2NWenjnH"
      },
      "outputs": [],
      "source": [
        "class ModelBuilderMoreAugmentation(metaclass= abc.ABCMeta):\n",
        "    \n",
        "    def initialize_path(self,project_folder):\n",
        "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())\n",
        "        self.val_doc = np.random.permutation(open(project_folder + '/' + 'val.csv').readlines())\n",
        "        self.train_path = project_folder + '/' + 'train'\n",
        "        self.val_path =  project_folder + '/' + 'val'\n",
        "        self.num_train_sequences = len(self.train_doc)\n",
        "        self.num_val_sequences = len(self.val_doc)\n",
        "        \n",
        "    def initialize_image_properties(self,image_height=100,image_width=100):\n",
        "        self.image_height=image_height\n",
        "        self.image_width=image_width\n",
        "        self.channels=3\n",
        "        self.num_classes=5\n",
        "        self.total_frames=30\n",
        "          \n",
        "    def initialize_hyperparams(self,frames_to_sample=30,batch_size=20,num_epochs=20):\n",
        "        self.frames_to_sample=frames_to_sample\n",
        "        self.batch_size=batch_size\n",
        "        self.num_epochs=num_epochs\n",
        "        \n",
        "        \n",
        "    def generator(self,source_path, folder_list, augment=False):\n",
        "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
        "        batch_size=self.batch_size\n",
        "        while True:\n",
        "            t = np.random.permutation(folder_list)\n",
        "            num_batches = len(t)//batch_size\n",
        "        \n",
        "            for batch in range(num_batches): \n",
        "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
        "                yield batch_data, batch_labels \n",
        "\n",
        "            remaining_seq=len(t)%batch_size\n",
        "        \n",
        "            if (remaining_seq != 0):\n",
        "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
        "                yield batch_data, batch_labels \n",
        "    \n",
        "    \n",
        "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
        "    \n",
        "        seq_len = remaining_seq if remaining_seq else batch_size\n",
        "    \n",
        "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
        "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
        "    \n",
        "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
        "\n",
        "        \n",
        "        for folder in range(seq_len): \n",
        "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
        "            for idx,item in enumerate(img_idx): \n",
        "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                image_resized=imresize(image,(self.image_height,self.image_width,3))\n",
        "            \n",
        "\n",
        "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
        "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
        "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
        "            \n",
        "                if (augment):\n",
        "                    shifted = cv2.warpAffine(image, \n",
        "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
        "                                            (image.shape[1], image.shape[0]))\n",
        "                    \n",
        "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
        "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
        "                    \n",
        "                    cropped=shifted[x0:x1,y0:y1,:]\n",
        "                    \n",
        "                    image_resized=imresize(cropped,(self.image_height,self.image_width,3))\n",
        "                    \n",
        "                    M = cv2.getRotationMatrix2D((self.image_width//2,self.image_height//2),\n",
        "                                                np.random.randint(-10,10), 1.0)\n",
        "                    rotated = cv2.warpAffine(image_resized, M, (self.image_width, self.image_height))\n",
        "                    \n",
        "                    #shifted = cv2.warpAffine(image_resized, \n",
        "                    #                        np.float32([[1, 0, np.random.randint(-3,3)],[0, 1, np.random.randint(-3,3)]]), \n",
        "                    #                        (image_resized.shape[1], image_resized.shape[0]))\n",
        "            \n",
        "                    batch_data_aug[folder,idx,:,:,0] = (rotated[:,:,0])/255\n",
        "                    batch_data_aug[folder,idx,:,:,1] = (rotated[:,:,1])/255\n",
        "                    batch_data_aug[folder,idx,:,:,2] = (rotated[:,:,2])/255\n",
        "                \n",
        "            \n",
        "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            \n",
        "    \n",
        "        if (augment):\n",
        "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
        "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
        "\n",
        "        \n",
        "        return(batch_data,batch_labels)\n",
        "    \n",
        "    \n",
        "    def train_model(self, model, augment_data=False):\n",
        "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
        "        val_generator = self.generator(self.val_path, self.val_doc)\n",
        "\n",
        "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "        if not os.path.exists(model_name):\n",
        "            os.mkdir(model_name)\n",
        "        \n",
        "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
        "        callbacks_list = [checkpoint, LR]\n",
        "\n",
        "        if (self.num_train_sequences%self.batch_size) == 0:\n",
        "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
        "        else:\n",
        "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
        "\n",
        "        if (self.num_val_sequences%self.batch_size) == 0:\n",
        "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
        "        else:\n",
        "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
        "    \n",
        "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
        "                            callbacks=callbacks_list, validation_data=val_generator, \n",
        "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
        "        return history\n",
        "\n",
        "        \n",
        "    @abc.abstractmethod\n",
        "    def define_model(self):\n",
        "        pass\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpWuos6DnjnI"
      },
      "outputs": [],
      "source": [
        "class Test(ModelBuilderMoreAugmentation):\n",
        "    def define_model(self):\n",
        "        pass\n",
        "\n",
        "test_generator=Test()\n",
        "test_generator.initialize_path(project_folder)\n",
        "test_generator.initialize_image_properties(image_height=160,image_width=160)\n",
        "test_generator.initialize_hyperparams(frames_to_sample=30,batch_size=3,num_epochs=1)\n",
        "\n",
        "g=test_generator.generator(test_generator.val_path,test_generator.val_doc,augment=True)\n",
        "batch_data, batch_labels=next(g)\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "axes[0].imshow(batch_data[0,29,:,:,:])   \n",
        "axes[1].imshow(batch_data[3,29,:,:,:])   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-9K-bM_njnI"
      },
      "source": [
        "## Model 9 with Augmentation\n",
        "### (3,3,3) Filter & 160x160 Image resolution - similar to Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SCGY76OnjnI"
      },
      "outputs": [],
      "source": [
        "class ModelConv3D9(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wz6R-8QnjnI"
      },
      "outputs": [],
      "source": [
        "conv_3d9=ModelConv3D9()\n",
        "conv_3d9.initialize_path(project_folder)\n",
        "conv_3d9.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d9.initialize_hyperparams(frames_to_sample=20,batch_size=20,num_epochs=20)\n",
        "conv_3d9_model=conv_3d9.define_model(dense_neurons=256,dropout=0.5)\n",
        "conv_3d9_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkqnwkk4njnI"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", conv_3d9_model.count_params())\n",
        "history_model9=conv_3d9.train_model(conv_3d9_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESP9o5k5njnI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "plot(history_model9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-mzZQBMnjnJ"
      },
      "source": [
        "## Model 10 with Augmentation\n",
        "### (2,2,2) Filter  & 120x120 Image resolution - similar to Model 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9hT3B08njnJ"
      },
      "outputs": [],
      "source": [
        "class ModelConv3D10(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-8PNHW2njnJ"
      },
      "outputs": [],
      "source": [
        "conv_3d10=ModelConv3D10()\n",
        "conv_3d10.initialize_path(project_folder)\n",
        "conv_3d10.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d10.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=25)\n",
        "conv_3d10_model=conv_3d10.define_model(filtersize=(2,2,2),dense_neurons=256,dropout=0.5)\n",
        "conv_3d10_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orGajVMSnjnJ"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", conv_3d10_model.count_params())\n",
        "history_model10=conv_3d10.train_model(conv_3d10_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRpCgZJZnjnJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "plot(history_model10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozqKxcWDnjnJ"
      },
      "source": [
        "## Model 11 with Augmentation\n",
        "### Adding more layers - Similar to model 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K01vH6_0njnJ"
      },
      "outputs": [],
      "source": [
        "class ModelConv3D11(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3aO3Q6YnjnJ"
      },
      "outputs": [],
      "source": [
        "conv_3d11=ModelConv3D11()\n",
        "conv_3d11.initialize_path(project_folder)\n",
        "conv_3d11.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d11.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
        "conv_3d11_model=conv_3d11.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.5)\n",
        "conv_3d11_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMd_kv_injnK"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", conv_3d11_model.count_params())\n",
        "history_model11=conv_3d11.train_model(conv_3d11_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9We3GVmnjnK"
      },
      "outputs": [],
      "source": [
        "plot(history_model11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxd-YwamnjnK"
      },
      "source": [
        "## Model 12 with Augmentation\n",
        "### Adding dropouts - Similar to Model 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_vwc92UnjnK"
      },
      "outputs": [],
      "source": [
        "class ModelConv3D12(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxSSp5w2njnK"
      },
      "outputs": [],
      "source": [
        "conv_3d12=ModelConv3D12()\n",
        "conv_3d12.initialize_path(project_folder)\n",
        "conv_3d12.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d12.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
        "conv_3d12_model=conv_3d12.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.25)\n",
        "conv_3d12_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5LtaWNFnjnK"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", conv_3d12_model.count_params())\n",
        "history_model12=conv_3d12.train_model(conv_3d12_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eClV1q40njnK"
      },
      "outputs": [],
      "source": [
        "plot(history_model12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kAlAcydnjnL"
      },
      "source": [
        "Model is overfitting badly !!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8qq__OknjnL"
      },
      "source": [
        "## Model 13 with Augmentation\n",
        "### Reducing network parameters - Similar to Model 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3rwYLrAnjnL"
      },
      "outputs": [],
      "source": [
        "class ModelConv3D13(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL6NFcV_njnL"
      },
      "outputs": [],
      "source": [
        "conv_3d13=ModelConv3D13()\n",
        "conv_3d13.initialize_path(project_folder)\n",
        "conv_3d13.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d13.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
        "conv_3d13_model=conv_3d13.define_model(dense_neurons=128,dropout=0.25)\n",
        "conv_3d13_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOEJq6IbnjnL"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", conv_3d13_model.count_params())\n",
        "history_model13=conv_3d13.train_model(conv_3d13_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l0Z_5EGnjnL"
      },
      "outputs": [],
      "source": [
        "plot(history_model13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_925yixdnjnL"
      },
      "source": [
        "## Model 14 with Augmentation\n",
        "###  Reducing network parameters again - Similar to model 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTZu3l4ZnjnL"
      },
      "outputs": [],
      "source": [
        "class ModelConv3D14(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (3, 3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxxDWyiDnjnM"
      },
      "outputs": [],
      "source": [
        "conv_3d14=ModelConv3D14()\n",
        "conv_3d14.initialize_path(project_folder)\n",
        "conv_3d14.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d14.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
        "conv_3d14_model=conv_3d14.define_model(dense_neurons=64,dropout=0.25)\n",
        "conv_3d14_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uLKqCJNnjnM"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", conv_3d14_model.count_params())\n",
        "history_model14=conv_3d14.train_model(conv_3d14_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYaZuRR0njnM"
      },
      "outputs": [],
      "source": [
        "plot(history_model14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PoahCF1njnM"
      },
      "source": [
        "## Model 15 with Augmentation\n",
        "### CNN LSTM with GRU - Similar to Model 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzyOywG_njnM"
      },
      "outputs": [],
      "source": [
        "class RNNCNN2(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
        "                                  input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "\n",
        "        model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "\n",
        "        model.add(GRU(lstm_cells))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(self.num_classes, activation='softmax'))\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9pV5J_qnjnM"
      },
      "outputs": [],
      "source": [
        "rnn_cnn2=RNNCNN2()\n",
        "rnn_cnn2.initialize_path(project_folder)\n",
        "rnn_cnn2.initialize_image_properties(image_height=120,image_width=120)\n",
        "rnn_cnn2.initialize_hyperparams(frames_to_sample=18,batch_size=20,num_epochs=20)\n",
        "rnn_cnn2_model=rnn_cnn2.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
        "rnn_cnn2_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN5pfTC2njnM"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", rnn_cnn2_model.count_params())\n",
        "history_model15=rnn_cnn2.train_model(rnn_cnn2_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMENznF9njnN"
      },
      "outputs": [],
      "source": [
        "plot(history_model15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "xfHcIYnsnjnN"
      },
      "source": [
        "### We see that overfitting is considerably high when we do more augmentation. However there is not much improvement on accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "wQ8KfWaknjnN"
      },
      "source": [
        "## Model 16 - Trying out transfer learning\n",
        "__(Optional)__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDEElRzbnjnN"
      },
      "outputs": [],
      "source": [
        "# importing the MobileNet model due to it's lightweight architecture and high speed performance as compared \n",
        "# to other heavy-duty models like VGG16, Alexnet, InceptionV3 etc. Also, we are now also running on low disk space \n",
        "# in the nimblebox.ai platform. \n",
        "\n",
        "from keras.applications import mobilenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjJ549NFnjnN"
      },
      "outputs": [],
      "source": [
        "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
        "\n",
        "class RNNCNN_TL(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(TimeDistributed(mobilenet_transfer,input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        \n",
        "        \n",
        "        for layer in model.layers:\n",
        "            layer.trainable = False\n",
        "        \n",
        "        \n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "        model.add(LSTM(lstm_cells))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(self.num_classes, activation='softmax'))\n",
        "        \n",
        "        \n",
        "        optimiser = optimizers.Adam()\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGLAbHEinjnN"
      },
      "outputs": [],
      "source": [
        "rnn_cnn_tl=RNNCNN_TL()\n",
        "rnn_cnn_tl.initialize_path(project_folder)\n",
        "rnn_cnn_tl.initialize_image_properties(image_height=120,image_width=120)\n",
        "rnn_cnn_tl.initialize_hyperparams(frames_to_sample=16,batch_size=5,num_epochs=20)\n",
        "rnn_cnn_tl_model=rnn_cnn_tl.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
        "rnn_cnn_tl_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "578TAT4GnjnN"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", rnn_cnn_tl_model.count_params())\n",
        "history_model16=rnn_cnn_tl.train_model(rnn_cnn_tl_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBnSY2jNnjnO"
      },
      "outputs": [],
      "source": [
        "plot(history_model16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "E7nltyhfnjnO"
      },
      "source": [
        "##### We are not training the mobilenet weights and we see validation accuracy is very poor. Let's train them as well and observe if there is performance improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqUrFjmwnjnO"
      },
      "source": [
        "## Model 17 - Transfer Learning with GRU and training all weights\n",
        "__(Optional)__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKEH4oKGnjnO"
      },
      "outputs": [],
      "source": [
        "from keras.applications import mobilenet\n",
        "\n",
        "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
        "\n",
        "class RNNCNN_TL2(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,gru_cells=64,dense_neurons=64,dropout=0.25):\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(TimeDistributed(mobilenet_transfer,input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        " \n",
        "        \n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "        model.add(GRU(gru_cells))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(self.num_classes, activation='softmax'))\n",
        "        \n",
        "        \n",
        "        optimiser = optimizers.Adam()\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfPQuUHenjnO"
      },
      "outputs": [],
      "source": [
        "rnn_cnn_tl2=RNNCNN_TL2()\n",
        "rnn_cnn_tl2.initialize_path(project_folder)\n",
        "rnn_cnn_tl2.initialize_image_properties(image_height=120,image_width=120)\n",
        "rnn_cnn_tl2.initialize_hyperparams(frames_to_sample=16,batch_size=5,num_epochs=20)\n",
        "rnn_cnn_tl2_model=rnn_cnn_tl2.define_model(gru_cells=128,dense_neurons=128,dropout=0.25)\n",
        "rnn_cnn_tl2_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0789PSrZnjnO"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", rnn_cnn_tl2_model.count_params())\n",
        "history_model17=rnn_cnn_tl2.train_model(rnn_cnn_tl2_model,augment_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpDDWkIpnjnO"
      },
      "outputs": [],
      "source": [
        "plot(history_model17)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTevp1DDnjnO"
      },
      "source": [
        "### Awesome results! 98% Training accuracy and 93% validation accuracy :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKnyVWoUnjnP"
      },
      "source": [
        "# Consolidated Final Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBIrMamknjnP"
      },
      "source": [
        "![png1.PNG](attachment:png1.PNG)\n",
        "![png2.PNG](attachment:png2.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBEtsI27njnP"
      },
      "source": [
        "## After doing all the experiments, we finalized Model 8 - CNN+LSTM, which performed well because it has \n",
        "\n",
        "  - (Training Accuracy : 93%, Validation Accuracy : 85%)\n",
        "\n",
        "  - Number of Parameters(1,657,445) less according to other models performance\n",
        "\n",
        "\n",
        "  - The best weights of CNN-LSTM: model.h5 (19 MB)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9avbJUAnjnP"
      },
      "source": [
        "# Loading model and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbRflQCEnjnP"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from keras.models import load_model\n",
        "model = load_model('model_init_2020-06-2522_00_52.036987/model-00020-0.19649-0.93514-0.45695-0.85000.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wzg44HZnjnP"
      },
      "outputs": [],
      "source": [
        "test_generator=RNNCNN1()\n",
        "test_generator.initialize_path(project_folder)\n",
        "test_generator.initialize_image_properties(image_height=120,image_width=120)\n",
        "test_generator.initialize_hyperparams(frames_to_sample=18,batch_size=20,num_epochs=20)\n",
        "\n",
        "g=test_generator.generator(test_generator.val_path,test_generator.val_doc,augment=False)\n",
        "batch_data, batch_labels=next(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1b9BasQnjnP"
      },
      "outputs": [],
      "source": [
        "batch_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVvUBt08njnP"
      },
      "outputs": [],
      "source": [
        "print(np.argmax(model.predict(batch_data[:,:,:,:,:]),axis=1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aVHZK11LnjnC",
        "-Ckwq3LAnjnC",
        "KvD1n0VrnjnD",
        "ygcFPbOZnjnE",
        "dgDyPcp9njnF",
        "2tMxr4nNnjnG",
        "PyWDLiI_njnG",
        "EYczHH8RnjnH",
        "q-9K-bM_njnI",
        "E-mzZQBMnjnJ",
        "ozqKxcWDnjnJ",
        "Lxd-YwamnjnK",
        "K8qq__OknjnL",
        "_925yixdnjnL",
        "6PoahCF1njnM",
        "xfHcIYnsnjnN",
        "wQ8KfWaknjnN",
        "aqUrFjmwnjnO",
        "YTevp1DDnjnO",
        "eBEtsI27njnP"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}